{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primeiro _prompt_ enviado ao ChatGpt:\n",
    "\n",
    "\n",
    "Gere em python um algoritmo que observe os seguintes requisitos:\n",
    "1. crie um algoritmo de árvore de decisão from scratch;\n",
    "2. não utilize bibliotecas como scikit learn ou quaisquer outras que implementem tal algoritmo;\n",
    "3. utilize a heurística top-down;\n",
    "4. utilize uma estratégia recursiva e gulosa (greedy);\n",
    "5. utilize quando necessário bibliotecas de manipulaçao de dados como Pandas e Numpy;\n",
    "6. os atributos poderão ser tanto categóricos, como numéricos (inteiro e float);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resposta do site:\n",
    "\n",
    "Aqui está uma implementação de um algoritmo de árvore de decisão from scratch que atende os requisitos:\n",
    "\n",
    "Top-down: O algoritmo começa da raiz e segue até as folhas.\n",
    "Recursivo e guloso (greedy): Ele escolhe, em cada nó, a melhor divisão (feature) com base na redução de entropia ou ganho de informação, e faz isso recursivamente para cada subdivisão.\n",
    "A implementação usa Numpy para manipulação de dados e cálculos de ganho de informação, e Pandas para manipulação de datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "class DecisionTree:\n",
    "    def __init__(self, max_depth=None, min_samples_split=2):\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.tree = None\n",
    "\n",
    "    def fit(self, X:pd.DataFrame, y):\n",
    "        dataset = X.copy()\n",
    "        dataset['label'] = y\n",
    "        self.tree = self._build_tree(dataset)\n",
    "\n",
    "    def predict(self, X:pd.DataFrame):\n",
    "        return X.apply(self._predict_row, axis=1)\n",
    "\n",
    "    def _entropy(self, y):\n",
    "        # Calcula a entropia dos rótulos\n",
    "        unique_classes, class_counts = np.unique(y, return_counts=True)\n",
    "        probabilities = class_counts / len(y)\n",
    "        return -np.sum(probabilities * np.log2(probabilities))\n",
    "\n",
    "    def _information_gain(self, left_y, right_y, parent_entropy):\n",
    "        # Calcula o ganho de informação após uma divisão\n",
    "        left_weight = len(left_y) / (len(left_y) + len(right_y))\n",
    "        right_weight = len(right_y) / (len(left_y) + len(right_y))\n",
    "        child_entropy = (left_weight * self._entropy(left_y) +\n",
    "                         right_weight * self._entropy(right_y))\n",
    "        return parent_entropy - child_entropy\n",
    "\n",
    "    def _best_split(self, dataset):\n",
    "        # Encontra a melhor divisão\n",
    "        best_gain = 0\n",
    "        best_feature = None\n",
    "        best_split_value = None\n",
    "        parent_entropy = self._entropy(dataset['label'])\n",
    "        \n",
    "        for feature in dataset.columns[:-1]:\n",
    "            values = dataset[feature].unique()\n",
    "            for value in values:\n",
    "                left_split = dataset[dataset[feature] <= value]\n",
    "                right_split = dataset[dataset[feature] > value]\n",
    "                \n",
    "                if len(left_split) == 0 or len(right_split) == 0:\n",
    "                    continue\n",
    "                \n",
    "                gain = self._information_gain(left_split['label'], right_split['label'], parent_entropy)\n",
    "                \n",
    "                if gain > best_gain:\n",
    "                    best_gain = gain\n",
    "                    best_feature = feature\n",
    "                    best_split_value = value\n",
    "        \n",
    "        return best_feature, best_split_value, best_gain\n",
    "\n",
    "    def _build_tree(self, dataset, depth=0):\n",
    "        # Função recursiva para construir a árvore de decisão\n",
    "        X = dataset.drop(columns=['label'])\n",
    "        y = dataset['label']\n",
    "        \n",
    "        # Critérios de parada\n",
    "        if len(np.unique(y)) == 1:\n",
    "            return np.unique(y)[0]  # Folha com uma única classe\n",
    "        if len(X) < self.min_samples_split or (self.max_depth is not None and depth >= self.max_depth):\n",
    "            return y.mode()[0]  # Folha com a classe majoritária\n",
    "        \n",
    "        # Melhor divisão\n",
    "        best_feature, best_split_value, best_gain = self._best_split(dataset)\n",
    "        \n",
    "        if best_gain == 0:\n",
    "            return y.mode()[0]  # Folha com a classe majoritária\n",
    "        \n",
    "        left_split = dataset[dataset[best_feature] <= best_split_value]\n",
    "        right_split = dataset[dataset[best_feature] > best_split_value]\n",
    "        \n",
    "        # Nós filhos\n",
    "        node = {\n",
    "            'feature': best_feature,\n",
    "            'value': best_split_value,\n",
    "            'left': self._build_tree(left_split, depth + 1),\n",
    "            'right': self._build_tree(right_split, depth + 1)\n",
    "        }\n",
    "        \n",
    "        return node\n",
    "\n",
    "    def _predict_row(self, row):\n",
    "        node = self.tree\n",
    "        while isinstance(node, dict):\n",
    "            if row[node['feature']] <= node['value']:\n",
    "                node = node['left']\n",
    "            else:\n",
    "                node = node['right']\n",
    "        return node\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Detalhes do Algoritmo:**\n",
    "- Heurística Top-Down: O algoritmo começa dividindo o dataset a partir da raiz (nó inicial), calculando a entropia de cada feature para determinar qual delas traz maior ganho de informação e faz a divisão baseada nesse cálculo. Esse processo é repetido recursivamente.\n",
    "\n",
    "- Estratégia Recursiva e Gulosa: A divisão de cada nó é escolhida de forma gulosa, isto é, para cada nó, o algoritmo tenta encontrar a melhor divisão naquele momento, sem considerar o impacto da escolha no futuro.\n",
    "\n",
    "### **Parâmetros:**\n",
    "`max_depth`: Limita a profundidade da árvore para evitar overfitting.\n",
    "`min_samples_split`: Define o número mínimo de amostras para permitir a divisão do nó.\n",
    "\n",
    "### **Exemplo de uso:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0\n",
      "1    0\n",
      "2    1\n",
      "3    1\n",
      "4    1\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Exemplo de uso com dataset fictício\n",
    "data = {'feature1': [1, 2, 2, 3, 3],\n",
    "        'feature2': [1, 1, 2, 2, 3],\n",
    "        'label': [0, 0, 1, 1, 1]}\n",
    "df = pd.DataFrame(data)\n",
    "X = df.drop(columns=['label'])\n",
    "y = df['label']\n",
    "\n",
    "tree = DecisionTree(max_depth=3)\n",
    "tree.fit(X, y)\n",
    "\n",
    "# Predições\n",
    "predictions = tree.predict(X)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
