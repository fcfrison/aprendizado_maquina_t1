{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prompt 1\n",
    "\n",
    "\n",
    "Gere em python um algoritmo que observe os seguintes requisitos:\n",
    "1. crie um algoritmo de árvore de decisão from scratch;\n",
    "2. não utilize bibliotecas como scikit learn ou quaisquer outras que implementem tal algoritmo;\n",
    "3. utilize a heurística top-down;\n",
    "4. utilize uma estratégia recursiva e gulosa (greedy);\n",
    "5. utilize quando necessário bibliotecas de manipulaçao de dados como Pandas e Numpy;\n",
    "6. os atributos poderão ser tanto categóricos, como numéricos (inteiro e float);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resposta ao prompt 1\n",
    "\n",
    "Aqui está uma implementação de um algoritmo de árvore de decisão from scratch que atende os requisitos:\n",
    "\n",
    "Top-down: O algoritmo começa da raiz e segue até as folhas.\n",
    "Recursivo e guloso (greedy): Ele escolhe, em cada nó, a melhor divisão (feature) com base na redução de entropia ou ganho de informação, e faz isso recursivamente para cada subdivisão.\n",
    "A implementação usa Numpy para manipulação de dados e cálculos de ganho de informação, e Pandas para manipulação de datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "class DecisionTree:\n",
    "    def __init__(self, max_depth=None, min_samples_split=2):\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.tree = None\n",
    "\n",
    "    def fit(self, X:pd.DataFrame, y):\n",
    "        dataset = X.copy()\n",
    "        dataset['label'] = y\n",
    "        self.tree = self._build_tree(dataset)\n",
    "\n",
    "    def predict(self, X:pd.DataFrame):\n",
    "        return X.apply(self._predict_row, axis=1)\n",
    "\n",
    "    def _entropy(self, y):\n",
    "        # Calcula a entropia dos rótulos\n",
    "        _, class_counts = np.unique(y, return_counts=True)\n",
    "        probabilities = class_counts / len(y)\n",
    "        return -np.sum(probabilities * np.log2(probabilities))\n",
    "\n",
    "    def _information_gain(self, left_y, right_y, parent_entropy):\n",
    "        # Calcula o ganho de informação após uma divisão\n",
    "        left_weight = len(left_y) / (len(left_y) + len(right_y))\n",
    "        right_weight = len(right_y) / (len(left_y) + len(right_y))\n",
    "        child_entropy = (left_weight * self._entropy(left_y) +\n",
    "                         right_weight * self._entropy(right_y))\n",
    "        return parent_entropy - child_entropy\n",
    "\n",
    "    def _best_split(self, dataset):\n",
    "        # Encontra a melhor divisão\n",
    "        best_gain = 0\n",
    "        best_feature = None\n",
    "        best_split_value = None\n",
    "        parent_entropy = self._entropy(dataset['label'])\n",
    "        \n",
    "        for feature in dataset.columns[:-1]:\n",
    "            values = dataset[feature].unique()\n",
    "            for value in values:\n",
    "                left_split = dataset[dataset[feature] <= value]\n",
    "                right_split = dataset[dataset[feature] > value]\n",
    "                \n",
    "                if len(left_split) == 0 or len(right_split) == 0:\n",
    "                    continue\n",
    "                \n",
    "                gain = self._information_gain(left_split['label'], right_split['label'], parent_entropy)\n",
    "                \n",
    "                if gain > best_gain:\n",
    "                    best_gain = gain\n",
    "                    best_feature = feature\n",
    "                    best_split_value = value\n",
    "        \n",
    "        return best_feature, best_split_value, best_gain\n",
    "\n",
    "    def _build_tree(self, dataset:pd.DataFrame, depth=0):\n",
    "        # Função recursiva para construir a árvore de decisão\n",
    "        X : pd.DataFrame = dataset.drop(columns=['label'])\n",
    "        y : np.array = dataset['label']\n",
    "        \n",
    "        # Critérios de parada\n",
    "        if len(np.unique(y)) == 1:\n",
    "            return np.unique(y)[0]  # Folha com uma única classe\n",
    "        if len(X) < self.min_samples_split or (self.max_depth is not None and depth >= self.max_depth):\n",
    "            return y.mode()[0]  # Folha com a classe majoritária\n",
    "        \n",
    "        # Melhor divisão\n",
    "        best_feature, best_split_value, best_gain = self._best_split(dataset)\n",
    "        \n",
    "        if best_gain == 0:\n",
    "            return y.mode()[0]  # Folha com a classe majoritária\n",
    "        \n",
    "        left_split = dataset[dataset[best_feature] <= best_split_value]\n",
    "        right_split = dataset[dataset[best_feature] > best_split_value]\n",
    "        \n",
    "        # Nós filhos\n",
    "        node = {\n",
    "            'feature': best_feature,\n",
    "            'value': best_split_value,\n",
    "            'left': self._build_tree(left_split, depth + 1),\n",
    "            'right': self._build_tree(right_split, depth + 1)\n",
    "        }\n",
    "        \n",
    "        return node\n",
    "\n",
    "    def _predict_row(self, row):\n",
    "        node = self.tree\n",
    "        while isinstance(node, dict):\n",
    "            if row[node['feature']] <= node['value']:\n",
    "                node = node['left']\n",
    "            else:\n",
    "                node = node['right']\n",
    "        return node\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Detalhes do Algoritmo:**\n",
    "- Heurística Top-Down: O algoritmo começa dividindo o dataset a partir da raiz (nó inicial), calculando a entropia de cada feature para determinar qual delas traz maior ganho de informação e faz a divisão baseada nesse cálculo. Esse processo é repetido recursivamente.\n",
    "\n",
    "- Estratégia Recursiva e Gulosa: A divisão de cada nó é escolhida de forma gulosa, isto é, para cada nó, o algoritmo tenta encontrar a melhor divisão naquele momento, sem considerar o impacto da escolha no futuro.\n",
    "\n",
    "**Parâmetros:**\n",
    "`max_depth`: Limita a profundidade da árvore para evitar overfitting.\n",
    "`min_samples_split`: Define o número mínimo de amostras para permitir a divisão do nó.\n",
    "\n",
    "**Exemplo de uso:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0\n",
      "1    0\n",
      "2    1\n",
      "3    1\n",
      "4    1\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Exemplo de uso com dataset fictício\n",
    "data = {'feature1': [1, 2, 2, 3, 3],\n",
    "        'feature2': [1, 1, 2, 2, 3],\n",
    "        'label': [0, 0, 1, 1, 1]}\n",
    "df = pd.DataFrame(data)\n",
    "X = df.drop(columns=['label'])\n",
    "y = df['label']\n",
    "\n",
    "tree = DecisionTree(max_depth=3)\n",
    "tree.fit(X, y)\n",
    "\n",
    "# Predições\n",
    "predictions = tree.predict(X)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prompt 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implemente, novamente sem utilizar bibliotecas como scikit learn, um algoritmo que retorne a matriz de confusão."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resposta prompt 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def confusion_matrix(y_true, y_pred, labels=None):\n",
    "    \"\"\"\n",
    "    Calcula a matriz de confusão para os rótulos verdadeiros e preditos.\n",
    "\n",
    "    Parâmetros:\n",
    "    y_true: array-like de rótulos verdadeiros.\n",
    "    y_pred: array-like de rótulos preditos.\n",
    "    labels: array-like dos rótulos únicos (opcional). Se não fornecido, será inferido a partir de y_true.\n",
    "\n",
    "    Retorna:\n",
    "    Uma matriz de confusão (DataFrame).\n",
    "    \"\"\"\n",
    "    if labels is None:\n",
    "        labels = np.unique(y_true)\n",
    "    \n",
    "    # Inicializa a matriz de confusão com zeros\n",
    "    matrix = pd.DataFrame(np.zeros((len(labels), len(labels)), dtype=int), index=labels, columns=labels)\n",
    "    \n",
    "    # Preenche a matriz com as contagens\n",
    "    for true_label, predicted_label in zip(y_true, y_pred):\n",
    "        matrix.at[true_label, predicted_label] += 1\n",
    "    \n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prompt 3\n",
    "Agora, gere funções em Python para calcular as seguintes métricas: acurácia, recall, precisão. Novamente, não utilize bibliotecas como scikit learn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resposta ao prompt 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def accuracy(conf_matrix):\n",
    "    \"\"\"\n",
    "    Calcula a acurácia a partir da matriz de confusão.\n",
    "    \n",
    "    Parâmetros:\n",
    "    conf_matrix: DataFrame (ou array) representando a matriz de confusão.\n",
    "    \n",
    "    Retorna:\n",
    "    Acurácia (float).\n",
    "    \"\"\"\n",
    "    total_correct = np.trace(conf_matrix)  # Soma dos elementos da diagonal principal (acertos)\n",
    "    total_samples = conf_matrix.sum().sum()  # Soma de todos os elementos da matriz (total de amostras)\n",
    "    return total_correct / total_samples\n",
    "\n",
    "def precision(conf_matrix):\n",
    "    \"\"\"\n",
    "    Calcula a precisão para cada classe a partir da matriz de confusão.\n",
    "    \n",
    "    Parâmetros:\n",
    "    conf_matrix: DataFrame (ou array) representando a matriz de confusão.\n",
    "    \n",
    "    Retorna:\n",
    "    Um dicionário com a precisão de cada classe.\n",
    "    \"\"\"\n",
    "    precisions = {}\n",
    "    for label in conf_matrix.columns:\n",
    "        true_positive = conf_matrix.at[label, label]  # Verdadeiros positivos (diagonal)\n",
    "        predicted_positive = conf_matrix[label].sum()  # Soma da coluna (todos os preditos como essa classe)\n",
    "        precisions[label] = true_positive / predicted_positive if predicted_positive > 0 else 0\n",
    "    return precisions\n",
    "\n",
    "def recall(conf_matrix):\n",
    "    \"\"\"\n",
    "    Calcula o recall para cada classe a partir da matriz de confusão.\n",
    "    \n",
    "    Parâmetros:\n",
    "    conf_matrix: DataFrame (ou array) representando a matriz de confusão.\n",
    "    \n",
    "    Retorna:\n",
    "    Um dicionário com o recall de cada classe.\n",
    "    \"\"\"\n",
    "    recalls = {}\n",
    "    for label in conf_matrix.index:\n",
    "        true_positive = conf_matrix.at[label, label]  # Verdadeiros positivos (diagonal)\n",
    "        actual_positive = conf_matrix.loc[label].sum()  # Soma da linha (todos os reais dessa classe)\n",
    "        recalls[label] = true_positive / actual_positive if actual_positive > 0 else 0\n",
    "    return recalls\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt 4\n",
    "Agora, gere um algoritmo, novamente sem utilizar scikit learn, para calcular o score f1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resposta ao Prompt 4\n",
    "O F1 Score é a média harmônica entre precisão (precision) e recall. Ele é usado para medir o equilíbrio entre essas duas métricas e é especialmente útil em problemas de classificação desbalanceados.\n",
    "Aqui está um algoritmo para calcular o F1 Score para cada classe, com base nas funções de precisão e recall que já implementamos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_score(conf_matrix):\n",
    "    \"\"\"\n",
    "    Calcula o F1 Score para cada classe a partir da matriz de confusão.\n",
    "    \n",
    "    Parâmetros:\n",
    "    conf_matrix: DataFrame (ou array) representando a matriz de confusão.\n",
    "    \n",
    "    Retorna:\n",
    "    Um dicionário com o F1 Score de cada classe.\n",
    "    \"\"\"\n",
    "    precisions = precision(conf_matrix)  # Calcula precisão\n",
    "    recalls = recall(conf_matrix)  # Calcula recall\n",
    "    f1_scores = {}\n",
    "\n",
    "    for label in conf_matrix.index:\n",
    "        p = precisions[label]\n",
    "        r = recalls[label]\n",
    "        if (p + r) > 0:\n",
    "            f1_scores[label] = 2 * (p * r) / (p + r)\n",
    "        else:\n",
    "            f1_scores[label] = 0  # Evita divisão por zero quando p + r = 0\n",
    "\n",
    "    return f1_scores\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Formatando o código da rotina principal\n",
    "**É esse trecho de código que executará a árvore de decisão."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fcfri\\AppData\\Local\\Temp\\ipykernel_14052\\2333426113.py:9: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['Age'].fillna(df['Age'].median(), inplace=True)\n",
      "C:\\Users\\fcfri\\AppData\\Local\\Temp\\ipykernel_14052\\2333426113.py:10: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['Embarked'].fillna(df['Embarked'].mode()[0], inplace=True)\n",
      "C:\\Users\\fcfri\\AppData\\Local\\Temp\\ipykernel_14052\\2333426113.py:11: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['Fare'].fillna(df['Fare'].median(), inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      0\n",
      "1      1\n",
      "2      1\n",
      "3      1\n",
      "4      0\n",
      "      ..\n",
      "886    0\n",
      "887    1\n",
      "888    0\n",
      "889    0\n",
      "890    0\n",
      "Length: 891, dtype: int64\n",
      "matriz de confusão:      0    1\n",
      "0  498   51\n",
      "1   81  261\n",
      "acurácia: 0.8518518518518519\n",
      "métrica: recall\n",
      "rótulo: 0, pontuação: 0.907103825136612\n",
      "rótulo: 1, pontuação: 0.7631578947368421\n",
      "métrica: precision\n",
      "rótulo: 0, pontuação: 0.8601036269430051\n",
      "rótulo: 1, pontuação: 0.8365384615384616\n",
      "métrica: f1 score\n",
      "rótulo: 0, pontuação: 0.8829787234042553\n",
      "rótulo: 1, pontuação: 0.7981651376146789\n"
     ]
    }
   ],
   "source": [
    "def imprime_dict(dict_instance:dict, metrica:str)->None:\n",
    "    print(f\"métrica: {metrica}\")\n",
    "    for key,value in dict_instance.items():\n",
    "        print(f\"rótulo: {key}, pontuação: {value}\")\n",
    "    return\n",
    "def pre_processing_titanic(df:pd.DataFrame)->pd.DataFrame:\n",
    "    df = df.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1)\n",
    "    # Handle missing values\n",
    "    df['Age'].fillna(df['Age'].median(), inplace=True)\n",
    "    df['Embarked'].fillna(df['Embarked'].mode()[0], inplace=True)\n",
    "    df['Fare'].fillna(df['Fare'].median(), inplace=True)\n",
    "    # Feature engineering\n",
    "    df['FamilySize'] = df['SibSp'] + df['Parch'] + 1\n",
    "    df['IsAlone'] = (df['FamilySize'] == 1).astype(int)\n",
    "    return df\n",
    "def main()->None:\n",
    "    df : pd.DataFrame = pd.read_csv(\"titanic.csv\")\n",
    "    tree : DecisionTree = DecisionTree(max_depth=5)\n",
    "    # Remove unnecessary columns\n",
    "    df = pre_processing_titanic(df)\n",
    "    # Prepare features and target\n",
    "    X = df.drop('Survived', axis=1)\n",
    "    y = df['Survived']\n",
    "    tree.fit(X,y)\n",
    "    predictions = tree.predict(X)\n",
    "    print(predictions)\n",
    "    conf_matrix_df : pd.DataFrame = confusion_matrix(y,predictions)\n",
    "    accuracy_value : float = accuracy(conf_matrix=conf_matrix_df)\n",
    "    recall_dict : dict = recall(conf_matrix=conf_matrix_df)\n",
    "    precision_dict :dict = precision(conf_matrix=conf_matrix_df)\n",
    "    f1_score_dict : dict = f1_score(conf_matrix=conf_matrix_df)\n",
    "    print(f\"matriz de confusão: {conf_matrix_df}\")\n",
    "    print(f\"acurácia: {accuracy_value}\")\n",
    "    imprime_dict(recall_dict,\"recall\")\n",
    "    imprime_dict(precision_dict,\"precision\")\n",
    "    imprime_dict(f1_score_dict,\"f1 score\")\n",
    "if __name__=='__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análise crítica do código gerado: \n",
    "1. pontos fortes,\n",
    "2. potenciais problemas/diferenças diante das implementações discutidas em aula\n",
    "3. opções de projeto realizadas pelo ChatGPT e seu impacto na implementação\n",
    "4. sugestões de melhorias"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
